{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee25d6c0-1c17-4497-bd74-f7795887d7e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "# Suppress warnings for a cleaner output.\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import requests\n",
    "import torch\n",
    "import intel_extension_for_pytorch as ipex  # Used for optimizing PyTorch models\n",
    "\n",
    "from io import BytesIO\n",
    "import torch.nn as nn\n",
    "import time\n",
    "from typing import List, Dict, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "060f24ed-81fc-4a76-8348-4d35dc4f1fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diffusion text to image generation model\n",
    "#print(f\"torch xpu device is available: {torch.xpu.is_available()}\")\n",
    "#print(f\"xpu device name: {torch.xpu.get_device_name()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6cc691d3-eaed-4712-a3e7-2150e2527cd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# install required dependencies\n",
    "%pip install transformers accelerate diffusers pillow >/dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d29d2285-ecbc-4bb1-ba5c-faf6e7b89c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from diffusers import DiffusionPipeline, DPMSolverMultistepScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be12d985-31b5-4a03-b976-74787558fc0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Text2ImgModel:\n",
    "    \"\"\"\n",
    "    Text2ImgModel is a class for generating images based on text prompts using a pretrained model.\n",
    "\n",
    "    Attributes:\n",
    "    - device: The device to run the model on. Default to \"xpu\" - Intel dGPUs.\n",
    "    - pipeline: The loaded model pipeline.\n",
    "    - data_type: The data type to use in the model.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        model_id_or_path: str,\n",
    "        device: str = \"xpu\",\n",
    "        torch_dtype: torch.dtype = torch.bfloat16,\n",
    "        optimize: bool = True,\n",
    "        enable_scheduler: bool = False,\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        The initializer for Text2ImgModel class.\n",
    "\n",
    "        Parameters:\n",
    "        - model_id_or_path: The identifier or path of the pretrained model.\n",
    "        - device: The device to run the model on. Default is \"xpu\".\n",
    "        - torch_dtype: The data type to use in the model. Default is torch.bfloat16.\n",
    "        - optimize: Whether to optimize the model after loading. Default is True.\n",
    "        \"\"\"\n",
    "\n",
    "        self.device = device\n",
    "        self.pipeline = self._load_pipeline(\n",
    "            model_id_or_path, torch_dtype, enable_scheduler\n",
    "        )\n",
    "        self.data_type = torch_dtype\n",
    "        if optimize:\n",
    "            start_time = time.time()\n",
    "            print(\"Optimizing the model...\")\n",
    "            self.optimize_pipeline()\n",
    "            self.warmup_model()\n",
    "            print(\n",
    "                \"Optimization completed in {:.2f} seconds.\".format(\n",
    "                    time.time() - start_time\n",
    "                )\n",
    "            )\n",
    "\n",
    "    def _load_pipeline(\n",
    "        self,\n",
    "        model_id_or_path: str,\n",
    "        torch_dtype: torch.dtype,\n",
    "        enable_scheduler: bool\n",
    "    ) -> DiffusionPipeline:\n",
    "        \"\"\"\n",
    "        Loads the pretrained model and prepares it for inference.\n",
    "\n",
    "        Parameters:\n",
    "        - model_id_or_path: The identifier or path of the pretrained model.\n",
    "        - torch_dtype: The data type to use in the model.\n",
    "\n",
    "        Returns:\n",
    "        - pipeline: The loaded model pipeline.\n",
    "        \"\"\"\n",
    "\n",
    "        print(\"Loading the model...\")\n",
    "        pipeline = DiffusionPipeline.from_pretrained(\n",
    "            model_id_or_path,\n",
    "            torch_dtype=torch_dtype,\n",
    "            use_safetensors=True,\n",
    "            variant=\"fp16\",\n",
    "        )\n",
    "        if enable_scheduler:\n",
    "            pipeline.scheduler = DPMSolverMultistepScheduler.from_config(\n",
    "                pipeline.scheduler.config\n",
    "            )\n",
    "        pipeline = pipeline.to(self.device)\n",
    "        print(\"Model loaded.\")\n",
    "        return pipeline\n",
    "\n",
    "    def _optimize_pipeline(self, pipeline: DiffusionPipeline) -> DiffusionPipeline:\n",
    "        \"\"\"\n",
    "        Optimizes the model for inference using ipex.\n",
    "\n",
    "        Parameters:\n",
    "        - pipeline: The model pipeline to be optimized.\n",
    "\n",
    "        Returns:\n",
    "        - pipeline: The optimized model pipeline.\n",
    "        \"\"\"\n",
    "\n",
    "        for attr in dir(pipeline):\n",
    "            if isinstance(getattr(pipeline, attr), nn.Module):\n",
    "                setattr(\n",
    "                    pipeline,\n",
    "                    attr,\n",
    "                    ipex.optimize(\n",
    "                        getattr(pipeline, attr).eval(),\n",
    "                        dtype=pipeline.text_encoder.dtype,\n",
    "                        inplace=True,\n",
    "                    ),\n",
    "                )\n",
    "        return pipeline\n",
    "\n",
    "    def warmup_model(self):\n",
    "        \"\"\"\n",
    "        Warms up the model by generating a sample image.\n",
    "        \"\"\"\n",
    "        print(\"Setting up model...\")\n",
    "        start_time = time.time()\n",
    "        self.generate_images(\n",
    "            prompt=\"A beautiful sunset over the mountains\",\n",
    "            num_images=1,\n",
    "            save_path=\"/tmp\",\n",
    "        )\n",
    "        print(\n",
    "            \"Model is set up and ready! Warm-up completed in {:.2f} seconds.\".format(\n",
    "                time.time() - start_time\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def optimize_pipeline(self) -> None:\n",
    "        \"\"\"\n",
    "        Optimizes the current model pipeline.\n",
    "        \"\"\"\n",
    "\n",
    "        self.pipeline = self._optimize_pipeline(self.pipeline)\n",
    "\n",
    "    def generate_images(\n",
    "        self,\n",
    "        prompt: str,\n",
    "        num_inference_steps: int = 50,\n",
    "        num_images: int = 5,\n",
    "        save_path: str = \"output\",\n",
    "    ) -> List[Image.Image]:\n",
    "        \"\"\"\n",
    "        Generates images based on the given prompt and saves them to disk.\n",
    "\n",
    "        Parameters:\n",
    "        - prompt: The text prompt to generate images from.\n",
    "        - num_inference_steps: Number of noise removal steps.\n",
    "        - num_images: The number of images to generate. Default is 5.\n",
    "        - save_path: The directory to save the generated images in. Default is \"output\".\n",
    "\n",
    "        Returns:\n",
    "        - images: A list of the generated images.\n",
    "        \"\"\"\n",
    "\n",
    "        images = []\n",
    "        for i in range(num_images):\n",
    "            with torch.xpu.amp.autocast(\n",
    "                enabled=True if self.data_type != torch.float32 else False,\n",
    "                dtype=self.data_type,\n",
    "            ):\n",
    "                image = self.pipeline(\n",
    "                    prompt=prompt,\n",
    "                    num_inference_steps=num_inference_steps,\n",
    "                    #negative_prompt=negative_prompt,\n",
    "                ).images[0]\n",
    "                if not os.path.exists(save_path):\n",
    "                    try:\n",
    "                        os.makedirs(save_path)\n",
    "                    except OSError as e:\n",
    "                        print(\"Failed to create directory\", save_path, \"due to\", str(e))\n",
    "                        raise\n",
    "            output_image_path = os.path.join(\n",
    "                save_path,\n",
    "                f\"{'_'.join(prompt.split()[:3])}_{i}.png\",\n",
    "            )\n",
    "            image.save(output_image_path)\n",
    "            images.append(image)\n",
    "        return images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8eaf6457-7a51-46ff-ad89-b496440866a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    model_ids = [\n",
    "        \"CompVis/stable-diffusion-v1-4\",\n",
    "        \"stabilityai/stable-diffusion-2-1\",\n",
    "        \"stabilityai/stable-diffusion-xl-base-1.0\",\n",
    "    ]\n",
    "\n",
    "    print(\"Available models are:\")\n",
    "    for i, model_id in enumerate(model_ids):\n",
    "        print(f\"{i + 1}. {model_id}\")\n",
    "\n",
    "    selected_model_index = (\n",
    "        int(\n",
    "            input(\n",
    "                \"Select a model by entering its number (or press enter to use the default model): \"\n",
    "            )\n",
    "        )\n",
    "        - 1\n",
    "    )\n",
    "    model_id = (\n",
    "        model_ids[selected_model_index]\n",
    "        if 0 <= selected_model_index < len(model_ids)\n",
    "        else model_ids[0]\n",
    "    )\n",
    "    model = Text2ImgModel(model_id, device=\"xpu\")\n",
    "    prompt = input(\"Please enter your prompt: \")\n",
    "    num_images = 0\n",
    "    try:\n",
    "        num_images = int(input(\"How many images have to be generated: \"))\n",
    "    except Exception:\n",
    "        num_images = 0\n",
    "    if num_images <= 0:\n",
    "        num_images = 1\n",
    "\n",
    "    enhancements = [\n",
    "        \"dark\",\n",
    "        \"purple light\",\n",
    "        \"dreaming\",\n",
    "        \"cyberpunk\",\n",
    "        \"ancient\" \", rustic\",\n",
    "        \"gothic\",\n",
    "        \"historical\",\n",
    "        \"punchy\",\n",
    "        \"photo\" \"vivid colors\",\n",
    "        \"4k\",\n",
    "        \"bright\",\n",
    "        \"exquisite\",\n",
    "        \"painting\",\n",
    "        \"art\",\n",
    "        \"fantasy [,/organic]\",\n",
    "        \"detailed\",\n",
    "        \"trending in artstation fantasy\",\n",
    "        \"electric\",\n",
    "        \"night\",\n",
    "    ]\n",
    "\n",
    "    prompt = prompt + \" \" + \" \".join(random.sample(enhancements, 5))\n",
    "    print(f\"Using enhanced prompt: {prompt}\")\n",
    "\n",
    "    try:\n",
    "        start_time = time.time()\n",
    "        model.generate_images(\n",
    "            prompt,\n",
    "            num_images=num_images,\n",
    "            save_path=\"./output\",\n",
    "        )\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\nUser interrupted image generation...\")\n",
    "    finally:\n",
    "        print(\n",
    "            f\"Complete generating {num_images} images in './output' in {time.time() - start_time:.2f} seconds.\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8d6b65-39b9-4472-b6a6-878e4c2cefdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available models are:\n",
      "1. CompVis/stable-diffusion-v1-4\n",
      "2. stabilityai/stable-diffusion-2-1\n",
      "3. stabilityai/stable-diffusion-xl-base-1.0\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Select a model by entering its number (or press enter to use the default model):  3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading pipeline components...: 100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 7/7 [00:01<00:00,  4.70it/s]"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9fb0a20-4915-4115-a673-daa8e1ef7ab0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "diffusion_xpu",
   "language": "python",
   "name": "diffusion_xpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
